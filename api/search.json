[{"id":"b53a009428ecfccfb037ac2f52a5ed28","title":"X-UI面板套用CDN加速","content":"X-UI面板套用CDN加速前期准备\nVPS\n域名\nCloudfare账号\n\nx-ui面板安装安装&amp;升级\nbash &lt;(curl -Ls https:&#x2F;&#x2F;raw.githubusercontent.com&#x2F;vaxilu&#x2F;x-ui&#x2F;master&#x2F;install.sh)\n\n执行后，根据提示依次输入用户名，密码，端口， 完成 X-ui 安装以后，我们可以输入 VPS的IP:端口 登录 X-ui 的管理面板（可以登录代表安装成功）\nssl证书申请在 VPS 输入 x-ui 命令，进入 X-ui 的命令菜单\n x-ui 面板管理脚本\n  0. 退出脚本\n————————————————\n  1. 安装 x-ui\n  2. 更新 x-ui\n  3. 卸载 x-ui\n————————————————\n  4. 重置用户名密码\n  5. 重置面板设置\n  6. 设置面板端口\n  7. 查看当前面板设置\n————————————————\n  8. 启动 x-ui\n  9. 停止 x-ui\n  10. 重启 x-ui\n  11. 查看 x-ui 状态\n  12. 查看 x-ui 日志\n————————————————\n  13. 设置 x-ui 开机自启\n  14. 取消 x-ui 开机自启\n————————————————\n  15. 一键安装 bbr (最新内核)\n  16. 一键申请SSL证书(acme申请)\n\n选择 16，申请 SSL 的证书,其中Cloudflare全局apikey，登录Cloudfare官网，在左下角的API区域，点击“获取您的API令牌” 申请成功以后，证书和密钥文件在 VPS 目录的 /root/cert 文件夹里面\n开启方法\n1、打开 DNS 解析页面的的 小云朵。\n\n2、找到 SSL/TLS 选项，把加密选项改为 完全/完全（严格）\n\n3、在 X-ui 面板建立 VLESS+WS+TLS 的代理节点\n\n面板套用CDN\n\nCloudflare 支持的 HTTPs 端口为： 443 2053 2083 2087 2096 8443；\n\n","slug":"vps/X-UI面板套用CDN加速","date":"2022-12-06T10:32:47.000Z","categories_index":"教程","tags_index":"vps","author_index":"Polnareff"},{"id":"8e7c1d29acf2deb8de0237bf4eef7e7d","title":"idea插件","content":"The Key Promoter X-学习快捷键利器，丢掉鼠标指日可待\n\n每次单击按钮/命令/菜单项上使用鼠标/ …它会显示一个弹出窗口，显示该操作的键盘快捷键。\n记录您没有使用键盘快捷键的统计数据，因此您知道它是值得学习的哪个捷径。\n\n\nCamel Case Plugin你还在为驼峰转下划线之类的问题苦恼嘛？\n\nsettings -&gt; 搜索camel 修改配置\n\n\n快捷键:    ⇧ + ⌥ + U / Shift + Alt + U\n\neasy_javadocIntelliJ IDEA的插件，能帮助java\\kotlin开发者自动生成javadoc\\kdoc文档注释，支持中文翻译\n\nwin默认快捷键\n\n\n快捷键\n作用域\n说明\n\n\n\nctrl \\\n类、方法、属性（光标放上面就行，不要双击选中！）\n生成当前文档注释\n\n\nctrl \\\n选中的中文\n生成选中的中文的英文命名\n\n\nctrl \\\n选中的非中文\n弹框展示翻译结果\n\n\nctrl shift \\\n类\n生成全部文档注释\n\n\nmac默认快捷键\n\n\n快捷键\n作用域\n说明\n\n\n\ncommand \\\n类、方法、属性（光标放上面就行，不要双击选中！）\n生成当前文档注释\n\n\ncommand \\\n选中的中文\n生成选中的中文的英文命名\n\n\ncommand \\\n选中的非中文\n弹框展示翻译结果\n\n\ncommand shift \\\n类\n生成全部文档注释\n\n\nFree-Idea-Mybatisfree-idea-mybatis是一款增强idea对mybatis支持的插件，主要功能如下：\n\n生成mapper xml文件\n快速从代码跳转到mapper及从mapper返回代码\nmybatis自动补全及语法错误提示\n集成mybatis generator gui界面\n\nLombok\n\n\n注解\n作用范围\n作用描述\n\n\n\n@Data\n类\n提供类所有属性的 get 、 set 、equals、canEqual、hashCode、toString 方法\n\n\n@Setter&amp;@Getter\n属性或类\n提供 get 、set方法\n\n\n@Log4j\n类\n为类提供一个 属性名为 log 的 log4j 日志对象，提供默认构造方法。\n\n\n@AllArgsConstructor\n类\n为类提供一个全参的构造方法，加了这个注解后，类中不提供默认构造方法了。\n\n\n@NoArgsConstructor\n类\n为类提供一个无参的构造方法。\n\n\n@EqualsAndHashCode\n类\n可以生成 equals、canEqual、hashCode 方法。\n\n\n@NonNull\n属性\n会自动产生一个关于此参数的非空检查，如果参数为空，则抛出一个空指针异常\n\n\n@Cleanup\n变量前\n保证变量的资源会被自动关闭，默认是调用资源的 close() 方法，可使用 @Cleanup(“methodName”) 来指定要调用的方法\n\n\n@ToString\n类\n生成所有参数的 toString 方法\n\n\n@Value\n类\n生成含所有参数的构造方法，get 方法，此外还提供了equals、hashCode、toString 方法\n\n\n@SneakyThrows\n方法\n生产try-catch包裹方法，@SneakyThrows(Exception.class) 的形式指定抛出哪种异常\n\n\nGsonFormat这是一个根据JSONObject格式的字符串,自动生成实体类\n\n\nDefault Option + s(Mac), Alt + s (win)\n\nJRebel mybatisPlus extension修改 mybatis 的 mapper.xml 文件不用重启项目\nGrep Console自定义控制台颜色\nRainbow Brackets彩色括号\n\n","slug":"工具/idea-pluging","date":"2022-12-03T10:32:47.000Z","categories_index":"插件","tags_index":"idea","author_index":"Polnareff"},{"id":"2893548a29e5cc54c91c39cae1cc175e","title":"mac工具","content":"超级右键-强大的macOS右键菜单工具\n\n新建文件TXT、RTF、XML、Word、Excel、PPT等\n复制/移动文件到，再也无需打开层层访达窗口来移动文件\n对于一些高频打开的目录，设置为常用目录，右键一键进入，快捷、方便！\n\nHomebrewmacOS（或 Linux）的包管理器\n安装:\n&#x2F;bin&#x2F;bash -c &quot;$(curl -fsSL https:&#x2F;&#x2F;raw.githubusercontent.com&#x2F;Homebrew&#x2F;install&#x2F;HEAD&#x2F;install.sh)&quot;","slug":"工具/mac工具","date":"2022-12-02T10:32:47.000Z","categories_index":"工具","tags_index":"idea","author_index":"Polnareff"},{"id":"2c2d68894e7c5f8bd5c444b2861a0caa","title":"java多语言整体总结","content":"1 页面上几种不同类型多语言\n    \n    \n\n\n\n页面上多语言（红色框对应的部分header&amp;footer）：这部分可以直接甩锅给前端的大哥\n后端接口数据涉及多语言（绿色框对应的部分）：通过多语言基表\n后端接口参数校验抛出的内容：i18n + 自定义Validator\n\n2 多语言基表设计\n\n\n字段\n类型\n描述\n\n\n\nid\nbigint\nid 自增\n\n\nsource_id\nvarchar\n来源id\n\n\nsource\nvarchar\n来源：表名\n\n\nfield\nvarchar\n字段名\n\n\nlang\nvarchar\nzh_CN、en_US\n\n\nvalue\nvarchar\n多语言相关内容，也可考虑存json文本\n\n\n:::tip\nsource_id、source、field &amp; lang 确定一个唯一数据\n:::\n\n3 i18n + 自定义Validator3.1 i18n配置@Bean\npublic MessageSource messageSource() &#123;\n    ReloadableResourceBundleMessageSource messageSource &#x3D; new ReloadableResourceBundleMessageSource();\n    messageSource.setBasename(&quot;classpath:messages&#x2F;validation&quot;);\n    messageSource.setCacheMillis(-1L);\n    messageSource.setDefaultEncoding(&quot;utf-8&quot;);\n    return messageSource;\n&#125;\n\nbasename: 多语言资源文件地址\ncacheMillis: 缓存加载的属性文件的毫秒数，1表示永远缓存\ndefaultEncoding: 解析属性文件的默认字符集\n\n3.2 自定义区域解析器从请求header中LANG或请求参数的lang来解析用户区域\n@Bean(name &#x3D; &quot;localeResolver&quot;)\npublic LocaleResolver getLocaleResolver() &#123;\n    return new I18nLocaleResolver();\n&#125;\n\n&#x2F;**\n * 获取请求头国际化信息\n *&#x2F;\nstatic class I18nLocaleResolver implements LocaleResolver &#123;\n\n    @NotNull\n    @Override\n    public Locale resolveLocale(HttpServletRequest request) &#123;\n        String language &#x3D; Optional.ofNullable(request.getHeader(&quot;LANG&quot;))\n                .orElse(request.getParameter(&quot;lang&quot;));\n        Locale locale &#x3D; Locale.getDefault();\n        if (Strings.isNotBlank(language)) &#123;\n\n            String[] split &#x3D; language.split(&quot;_&quot;);\n            locale &#x3D; new Locale(split[0], split[1]);\n        &#125;\n        return locale;\n    &#125;\n\n    @Override\n    public void setLocale(@NotNull HttpServletRequest httpServletRequest, HttpServletResponse httpServletResponse, Locale locale) &#123;\n\n    &#125;\n&#125;\n\nLocaleResolver bean的name要设置为localeResolver，原因参考下面源码。\n\nprivate void initLocaleResolver(ApplicationContext context) &#123;\n   try &#123;\n      this.localeResolver &#x3D; context.getBean(LOCALE_RESOLVER_BEAN_NAME, LocaleResolver.class);\n      if (logger.isTraceEnabled()) &#123;\n         logger.trace(&quot;Detected &quot; + this.localeResolver);\n      &#125;\n      else if (logger.isDebugEnabled()) &#123;\n         logger.debug(&quot;Detected &quot; + this.localeResolver.getClass().getSimpleName());\n      &#125;\n   &#125;\n   catch (NoSuchBeanDefinitionException ex) &#123;\n      &#x2F;&#x2F; We need to use the default.\n      this.localeResolver &#x3D; getDefaultStrategy(context, LocaleResolver.class);\n      if (logger.isTraceEnabled()) &#123;\n         logger.trace(&quot;No LocaleResolver &#39;&quot; + LOCALE_RESOLVER_BEAN_NAME +\n               &quot;&#39;: using default [&quot; + this.localeResolver.getClass().getSimpleName() + &quot;]&quot;);\n      &#125;\n   &#125;\n&#125;\n\n3.3 统一参数异常处理@ExceptionHandler(value &#x3D; BindException.class)\n@ResponseBody\npublic GenericResult bindExceptionHandler(BindException e) &#123;\n    String message &#x3D; e.getAllErrors().stream()\n            .map(DefaultMessageSourceResolvable::getDefaultMessage).collect(Collectors.joining(&quot;,&quot;));\n    return GenericResult.fail(&quot;400&quot;, message);\n&#125;\n\n这里一般转换为自己项目的自定义异常\n","slug":"多语言/java多语言整体总结","date":"2022-01-02T10:32:47.000Z","categories_index":"学习总结","tags_index":"i18n","author_index":"Polnareff"},{"id":"54834ecc59dd7f27dd6659dff94113cd","title":"提效大礼包","content":"The Key Promoter X学习快捷键利器，丢掉鼠标指日可待\n\n每次单击按钮/命令/菜单项上使用鼠标/ …它会显示一个弹出窗口，显示该操作的键盘快捷键。\n记录您没有使用键盘快捷键的统计数据，因此您知道它是值得学习的哪个捷径。\n\n\nCamel Case Plugin你还在为驼峰转下划线之类的问题苦恼嘛？\n\nFree-Idea-Mybatisfree-idea-mybatis是一款增强idea对mybatis支持的插件，主要功能如下： \n\n生成mapper xml文件\n快速从代码跳转到mapper及从mapper返回代码\nmybatis自动补全及语法错误提示\n集成mybatis generator gui界面\n\nIDEA的 Live Template模版用得好摸鱼时间多一半\n推荐：\n编程小技巧之IDEA的Live Template\nLombok\n\n\n注解\n作用范围\n作用描述\n\n\n\n@Data\n类\n提供类所有属性的 get 、 set 、equals、canEqual、hashCode、toString 方法\n\n\n@Setter&amp;@Getter\n属性或类\n提供 get 、set方法\n\n\n@Log4j\n类\n为类提供一个 属性名为 log 的 log4j 日志对象，提供默认构造方法。\n\n\n@AllArgsConstructor\n类\n为类提供一个全参的构造方法，加了这个注解后，类中不提供默认构造方法了。\n\n\n@NoArgsConstructor\n类\n为类提供一个无参的构造方法。\n\n\n@EqualsAndHashCode\n类\n可以生成 equals、canEqual、hashCode 方法。\n\n\n@NonNull\n属性\n会自动产生一个关于此参数的非空检查，如果参数为空，则抛出一个空指针异常\n\n\n@Cleanup\n变量前\n保证变量的资源会被自动关闭，默认是调用资源的 close() 方法，可使用 @Cleanup(“methodName”) 来指定要调用的方法\n\n\n@ToString\n类\n生成所有参数的 toString 方法\n\n\n@Value\n类\n生成含所有参数的构造方法，get 方法，此外还提供了equals、hashCode、toString 方法\n\n\n@SneakyThrows\n方法\n生产try-catch包裹方法，@SneakyThrows(Exception.class) 的形式指定抛出哪种异常\n\n\nGsonFormat这是一个根据JSONObject格式的字符串,自动生成实体类\n\nCodota：代码智能提示Go to Plugins/Marketplace tab, Search “Tabnine“ and click Install\n\nTODO","slug":"工具/提效大礼包","date":"2021-06-02T10:32:47.000Z","categories_index":"教程","tags_index":"tools","author_index":"Polnareff"},{"id":"7a07eb5d59a9e9ff4655ee40e094d0bf","title":"代码量统计工具-GitStats","content":"GitStatsGit历史统计生成数据表：\n\n一般统计：总文件，行，提交，作者。\n活动：按小时，周，年，等。\n作者：作者列表（名称，提交（％），首次提交日期，最后提交日期，年龄，年份，年度作者。\n文件：文件计数到日期，扩展\n行：代码线按日期\n\n1.克隆项目\ngit clone git:&#x2F;&#x2F;github.com&#x2F;hoxu&#x2F;gitstats.git\n\n2.第二步将gitstats拷贝为gitstats.py\ncd gitstats&#x2F;\ncp gitstats gitstats.py\n\nmac用户得装一个Gnuplot（一个命令行的交互式绘图工具）\nbrew install gnuplot\n\n3.统计命令\npython gitstats.py ..&#x2F;project&#x2F;pulsar .&#x2F;pulsar\n\n../project/pulsar：工程目录\n./pulsar：结果存放目录\n这里用pulsar来实验一下：\npython gitstats.py ..&#x2F;project&#x2F;pulsar .&#x2F;pulsar\n\ndemo展示地址：https://jp-polnareff.github.io/demo/pulsar/index.html\n","slug":"工具/代码量统计","date":"2021-06-02T10:32:47.000Z","categories_index":"工具","tags_index":"tools","author_index":"Polnareff"},{"id":"265980696829f8e89187dcd1752370ec","title":"GraphQL初探","content":"简介A query language for your API\nAPI的查询语言，是用于使用现有数据来完成这些查询的运行时。GraphQL为您的API中的数据提供了完整且易于理解的描述，使客户能够准确地询问他们需要什么。\n","slug":"network/graphql初探","date":"2021-05-16T10:32:47.000Z","categories_index":"学习记录","tags_index":"GraphQL","author_index":"Polnareff"},{"id":"0ae44ea2c5de8fc0dba98b172b9416ad","title":"AWK 样式扫描和处理语言","content":"AWK 样式扫描和处理语言简介AWK（其名称得自于它的创始人阿尔佛雷德·艾侯、彼得·温伯格和布莱恩·柯林汉姓氏的首个字母）是一种优良的文本处理工具，Linux及Unix环境中现有的功能最强大的数据处理引擎之一。AWK提供了极其强大的功能：可以进行正则表达式的匹配，样式装入、流控制、数学运算符、进程控制语句甚至于内置的变量和函数。\n该工具扫描文件中的每一行，查找与命令行中所给定内容相匹配的模式。如果发现匹配内容，则进行下一个编程步骤。如果找不到匹配内容，则继续处理下一行。\n命令awk [ -F fs ] [ -v var&#x3D;value ] [ &#39;prog&#39; | -f progfile ] [ file ...  ]\n\n\n-F s ：指定输入文件折分隔符，fs是一个字符串或者是一个正则表达式\n-v var=value：赋值一个用户定义变量\n-f progfile：从脚本文件中读取awk命令\n\n内建变量AWK的内建变量包括域变量，例如$1, $2, $3，以及\n\n$0：整行记录\n$1, $2, $3...：分别被分隔符分割的1,2,3…词\nNR：已经读出的记录数，就是行号，从1开始\nNF：一条记录的字段的数目\nFILENAME：当前输入文件的文件名。\nFS：“字段分隔符”，字段分隔符(默认是任何空格)。\nRS：记录分隔符(默认是一个换行符)\nOFS：“输出字段分隔符，默认值与输入字段分隔符一致。\nORS：输出记录分隔符(默认值是一个换行符)\nOFMT：数字的输出格式(默认值是%.6g)\n\n内置函数awk脚本#运行前\nBEGIN &#123;\n\n&#125;\n#运行中\n&#123;\n\n&#125;\n#运行后\nEND &#123;\n\n&#125;\n\n\n\n常见案例# 邮件列表\n$ cat mail-list\n阿米莉亚555-5553 amelia.zodiacusque@gmail.com F\n安东尼555-3412 anthony.asserturo@hotmail.com A\n贝基555-7685 becky.algebrarum@gmail.com A\n第555-1675号法案bill.drowning@hotmail.com A\n布罗德里克555-0542 broderick.aliquotiens@yahoo.com R\n卡米拉555-2912 camilla.infusarum@skynet.be R\nFabius 555-1234 fabius.undevicesimus@ucb.edu F\n朱莉555-6699 julie.perscrutabor@skeeve.com F\n马丁555-6480 martin.codicibus@hotmail.com A\n塞缪尔555-3430 samuel.lanceolis@shu.edu A\n让·保罗555-2127 jeanpaul.campanorum@nyu.edu R\n# 库存发货：绿红橙蓝包装每个月出货的数量\n$ cat inventory-shipped\nJan  13  25  15 115\nFeb  15  32  24 226\nMar  15  24  34 228\nApr  31  52  63 420\nMay  16  34  29 208\nJun  31  42  75 492\nJul  24  34  67 436\nAug  15  34  47 316\nSep  13  55  37 277\nOct  29  54  68 525\nNov  20  87  82 577\nDec  17  35  61 401\n\nJan  21  36  64 620\nFeb  26  58  80 652\nMar  24  75  70 495\nApr  21  70  74 514\n\n带gmail的数据行\nawk &#39;&#x2F;gmail&#x2F; &#123; print $0 &#125;&#39; mail-list\n\n长度大于50\nawk &#39;length($0) &gt; 50&#39; mail-list\n\n打印最长数据行长度\nawk &#39;&#123; if (length($0) &gt; max) max &#x3D; length($0) &#125;\n     END &#123; print max &#125;&#39; mail-list\n# 或     \nexpand mail-list | awk &#39;&#123; if (x &lt; length($0)) x &#x3D; length($0) &#125;\n                   END &#123; print &quot;maximum line length is &quot; x &#125;&#39;     \n\n打印至少有一个字读的数据行\nawk &#39;NF &gt; 0&#39; inventory-shipped\n\n打印文件列表字节总数\nls -l | awk &#39;&#123; x +&#x3D; $5 &#125;\n                   END &#123; print &quot;total bytes: &quot; x &#125;&#39;\n\n打印所有用户的登录名的排序列表\nawk -F: &#39;&#123; print $1 &#125;&#39; &#x2F;etc&#x2F;passwd | sort\n\n打印邮件列表行数\nawk &#39;END &#123; print NR &#125;&#39; mail-list\n\nmail-list中查带12的，inventory-shipped中查带27的\nawk &#39;&#x2F;12&#x2F; &#123; print $0 &#125; ;\n      &#x2F;27&#x2F; &#123; print $0 &#125;&#39; mail-list inventory-shipped\n\n统计project目录下java文件行数\nfind .&#x2F;project -name &quot;*.java&quot;\\\n| xargs awk &#39;END&#123;print NR&#125;&#39;\\\n| awk &#39;&#123;sum +&#x3D; $0&#125; END &#123; print &quot;sum &quot; sum &#125;&#39;\n\n统计一个大文本中单词出现次数最高的3个单词\nawk &#39;&#123;for(i&#x3D;1;i&lt;&#x3D;NF;i++)sum[$i]++&#125; END &#123;for(k in sum) print k &quot;:&quot; sum[k]&#125;&#39; inventory-shipped \\\n| sort -n -k 2 -t : -r \\\n| head -3\n\n","slug":"linux/awk","date":"2021-04-15T10:32:47.000Z","categories_index":"学习记录","tags_index":"Linux","author_index":"Polnareff"},{"id":"55ea1ac8b6eebb4c3c1010cae15373f5","title":"Pulsar之message篇","content":"Pulsar之message篇Pulsar建立在pub-sub上，该设计模式中，producer 发布消息到 topic， Consumer 订阅 topic、处理发布的消息，并在处理完成后发送确认。\n一旦创建订阅，即使 consumer 断开连接，Pulsar 仍然可以保存所有消息。 在 consumer 确认消息已处理成功后，才会删除消息。\nmessage\n\n\nComponent\nDescription\n\n\n\nValue / data payload\n消息所承载的数据。 尽管消息数据也可以符合数据 schemas，但所有 Pulsar 消息都包含原始字节。\n\n\nKey\n消息可以选择用键进行标记，这在 topic 压缩等操作很有用。\n\n\nProperties\n用户自定义属性的键值对（可选）。\n\n\nProducer name\n生成消息的 producer 的名称。 如果不指定，则使用默认名称\n\n\nSequence ID\n每个 Pulsar 消息都存储在其主题上的有序序列中。消息的序列 ID 是其在该序列中的顺序。\n\n\nPublish time\n消息发布的时间戳，由 producer 自动添加。\n\n\nEvent time\n应用程序可以附加到消息的时间戳（可选）， 例如处理消息的时间。 如果没有明确设置，则消息的事件时间为 0。\n\n\nTypedMessageBuilder\n用于构造消息。 您可以使用 TypedMessageBuilder 设置消息的键值对属性。在设置 TypedMessageBuilder 时，最佳的选择是将 key 设置为字符串。 如果将 key 设置为其他类型（例如，AVRO 对象），则 key 会以字节形式发送，这时 consumer 就很难使用了。\n\n\nmessage默认大小问5M，自定义修改：\nbroker.conf  中\n# The max size of a message (in bytes).\nmaxMessageSize&#x3D;5242880\n\nbookkeeper.conf  中\n# 收到的任何大于此值的消息都将被拒绝\nnettyMaxFrameSizeBytes&#x3D;5253120\n\n\n\nProducer\n\n\n发送模式\nDescription\n\n\n\n同步发送\nProducer 将在发送每条消息后等待 broker 的确认。 如果未收到确认，则 producer 将认为发送失败。\n\n\n异步发送\nProducer 将把消息放于阻塞队列中，并立即返回然后，客户端将在后台将消息发送给 broker。\n\n\nProducer API提供了4种不同的选项，用于将消息发送到代理：\n\n同步单发布\n异步单发布\n同步批量发布\n异步批量发布（我们的选择，异步发送具有重试机制，最大重试计数设置为10）\n\nreturn pulsarClient.newProducer(Schema.STRING)\n  .topic(xxx)\n  &#x2F;&#x2F; 10ms或者队列message达到100发送\n  .batchingMaxPublishDelay(10, TimeUnit.MILLISECONDS)\n  .batchingMaxMessages(100)\n  &#x2F;&#x2F; 如果在sendTimeout到期之前服务器未确认消息，则将报告错误。\n  .sendTimeout(10, TimeUnit.SECONDS)\n  &#x2F;&#x2F; 消息队列已满时，阻塞\n  .blockIfQueueFull(true)\n  .create();\n&#x2F;&#x2F; 其余还可自行设置messageRoutingMode、compressionType等等\n&#x2F;&#x2F;compressionType支持LZ4、ZLIB、ZSTD、SNAPPY四种\n\nPulsar具有重复数据删除机制以提供精确的一次处理。启用重复数据删除后，Pulsar代理将删除重复的消息。它通过查看SequenceId在发布时添加的消息字段来检测重复项。\n路由模式有三种 MessageRoutingMode 可用:\n\n\n\n发送模式\nDescription\n\n\n\nRoundRobinPartition\n如果消息没有指定 key，为了达到最大吞吐量，消息会以 round-robin 方式被路由所有分区。 如果为消息指定了key，发往分区的消息会被分区生产者根据 key 做 hash，然后分散到对应的分区上。\n\n\nSinglePartition\n如果消息没有指定 key，生产者将会随机选择一个分区，并发送所有消息。 如果为消息指定了key，发往分区的消息会被分区生产者根据 key 做 hash，然后分散到对应的分区上。\n\n\nCustomPartition\n使用自定义消息路由，可以定制消息如何进入特定的分区。\n\n\n消息的顺序与MessageRoutingMode和Message Key相关：\n\n使用 SinglePartition 或 RoundRobinPartition 模式，每条消息都有key，所有具有相同 key 的消息将按顺序排列并放置在相同的分区（Partition）中。\n路由策略为SinglePartition, 且每条消息都没有key，来自同一生产者的所有消息都是有序的。\n\nConsumerConsumer提供了三类获取消息的方式：\n\n同步接收消息\n异步接收消息：通过Future返回消息\n通过MessageListener返回消息（目前在用的）\n\nAt least once 模型：\npublic abstract class AbstractMessageListener&lt;T&gt; implements MessageListener&lt;T&gt; &#123;\n\n    @Override\n    public void received(Consumer&lt;T&gt; consumer, Message&lt;T&gt; message) &#123;\n        try &#123;\n            &#x2F;&#x2F; processing\n            consumer.acknowledge(message);\n        &#125; catch (Exception e) &#123;\n            consumer.negativeAcknowledge(message);\n        &#125;\n    &#125;\n&#125;\n\nAt most once 模型：\npublic abstract class AbstractMessageListener&lt;T&gt; implements MessageListener&lt;T&gt; &#123;\n\n    @Override\n    public void received(Consumer&lt;T&gt; consumer, Message&lt;T&gt; message) &#123;\n        try &#123;\n            &#x2F;&#x2F; processing\n        &#125; catch (Exception e) &#123;\n            log.error(&quot;processing error&quot;, e);\n        &#125; finally &#123;\n            consumer.acknowledge(message);\n        &#125;\n    &#125;\n&#125;\n\nreturn pulsarClient.newConsumer(Schema.STRING)\n  \t\t\t&#x2F;&#x2F; 订阅的topic列表\n        .topics(Collections.singletonList(xxxtopic))\n  \t\t\t&#x2F;&#x2F; 消费名称\n        .consumerName(x x x)\n  \t\t\t&#x2F;&#x2F; 订阅方式Exclusive、Shared、Failover、Key_Shared\n        .subscriptionType(SubscriptionType.Shared)\n  \t\t\t&#x2F;&#x2F; 订阅名称\n        .subscriptionName(xxx)\n  \t\t\t&#x2F;&#x2F; 从哪里开始消费\n  \t\t\t&#x2F;&#x2F; Latest 最新位置，这意味着开始消费位置将是最后一条消息\n  \t\t\t&#x2F;&#x2F; Earliest 最早的位置，这意味着开始消费的位置将是第一条消息\n        .subscriptionInitialPosition(SubscriptionInitialPosition.Latest)\n  \t\t\t&#x2F;&#x2F; 自己的linstener实现类\n        .messageListener(AbstractMessageListenerImpl)\n        .subscribe();\n\nMessages的两种方式确认消息：\n\n单条确认模式：消息被单独确认，消费者需要确认每个消息，并将确认请求发送给broker。\n累积确认模式：消费者只需要确认最后一条他收到的消息。 所有之前（包含此条）的消息，都不会被再次发送给那个消费者。\n\n\n在共享订阅模式，消息都是单条确认模式\n\n订阅模式\n\nExclusive：在独占模式下，仅允许单个使用者附加到订阅。如果多个使用者使用相同的订阅来订阅主题，则会发生错误\nFailover：Failover模式中，多个consumer可以绑定到同一个subscription。当主消费者断开连接时，所有（未确认和后续的）消息都会被发送、交付给下一个消费者。\nShared：消息通过round robin轮询机制分发给不同的消费者，并且每个消息仅会被分发给一个消费者。 当消费者断开连接，所有被发送给他，但没有被确认的消息将被重新安排，分发给其它存活的消费者。\nKey_Shared：按 KEY 共享消费，多对多，Exclusive 和 Shared 的折中模式\n\nTopicDead letter topic死信主题使您可以在使用者无法成功使用某些消息时使用新消息。 在这种机制下，无法使用的消息将存储在一个单独的主题中，该主题称为死信主题。\nConsumer&lt;byte[]&gt; consumer &#x3D; pulsarClient.newConsumer(Schema.BYTES)\n              .topic(topic)\n              .subscriptionName(&quot;my-subscription&quot;)\n              .subscriptionType(SubscriptionType.Shared)\n              .deadLetterPolicy(DeadLetterPolicy.builder()\n                    .maxRedeliverCount(maxRedeliveryCount)\n                    .deadLetterTopic(&quot;your-topic-name&quot;)\n                    .build())\n              .subscribe();\n\n\n死信主题仅在共享订阅模式下启用\n\nRetry letter topic对于许多在线业务系统，由于业务逻辑处理中发生异常，因此会重新使用一条消息。 要配置重用失败消息的延迟时间，可以配置生产者以将消息发送到业务主题和重试主题，并在使用者上启用自动重试。 在使用者上启用自动重试后，如果消息未被消费，则消息会存储在重试主题中，因此，consumer在指定的延迟时间后会自动消费来自重试主题的失败消息\n默认情况下，自动重试处于禁用状态。 您可以将enableRetry设置为true以对使用者启用自动重试。\nConsumer&lt;byte[]&gt; consumer &#x3D; pulsarClient.newConsumer(Schema.BYTES)\n                .topic(topic)\n                .subscriptionName(&quot;my-subscription&quot;)\n                .subscriptionType(SubscriptionType.Shared)\n                .enableRetry(true)\n                .receiverQueueSize(100)\n                .deadLetterPolicy(DeadLetterPolicy.builder()\n                        .maxRedeliverCount(maxRedeliveryCount)\n                        .retryLetterTopic(&quot;persistent:&#x2F;&#x2F;my-property&#x2F;my-ns&#x2F;my-subscription-custom-Retry&quot;)\n                        .build())\n                .subscriptionInitialPosition(SubscriptionInitialPosition.Earliest)\n                .subscribe();\n\nPartitioned topics分区主题实际是通过在底层拥有 N 个内部主题来实现的，这个 N 的数量就是等于分区的数量。 当向分区的topic发送消息，每条消息被路由到其中一个broker。 Pulsar自动处理跨broker的分区分布。\n假如一个topic的消息被广播给两个consumer。 路由模式确定每条消息该发往哪个分区，而订阅模式确定消息传递给哪个消费者。吞吐能力的要求，决定了 分区/路由 的方式。\nNon-persistent topicsPulsar支持非持久性主题，这些主题的消息从不持久存储到磁盘，只存在于内存中。 Pulsar也提供了非持久topic。非持久topic的消息不会被保存在硬盘上，只存活于内存中。当使用非持久topic分发时，杀掉Pulsar的broker或者关闭订阅者，此topic（ non-persistent)）上所有的瞬时消息都会丢失，意味着客户端可能会遇到消息缺失。\n","slug":"mq/pulsar_message","date":"2021-04-06T10:32:47.000Z","categories_index":"学习记录","tags_index":"Pulsar","author_index":"Polnareff"},{"id":"3256cb14c92d99ae1c7a0ab0e2019e03","title":"软链接&硬链接","content":"软链接&amp;硬链接什么是链接？链接简单说实际上是一种文件共享的方式，是 POSIX 中的概念，主流文件系统都支持链接文件。\ninode**inode (index node)**是指在许多“类Unix文件系统”中的一种数据结构，用于描述文件系统对象（包括文件、目录、设备文件、socket、管道等）。每个inode保存了文件系统对象数据的属性和磁盘块位置。文件系统对象属性包含了各种元数据（如：最后修改时间） ，也包含用户组（owner ）和权限数据。\nPOSIX标准强制规范了文件系统的行为。每个“文件系统对象”必须具有：\n\n以字节为单位表示的文件大小。\n设备ID，标识容纳该文件的设备。\n文件所有者的User ID。\n文件的Group ID\n文件的模式（mode），确定了文件的类型，以及它的所有者、它的group、其它用户访问此文件的权限。\n额外的系统与用户标志（flag），用来保护该文件。\n3个时间戳，记录了inode自身被修改（ctime, inode change time）、文件内容被修改（mtime, modification time）、最后一次访问（atime, access time）的时间。\n1个链接数，表示有多少个硬链接指向此inode。\n到文件系统存储位置的指针。通常是1K字节或者2K字节的存储容量为基本单位。\n\n文件名与 inode Linux 中文件名和文件数据（inode 节点）是分开存储与管理的，并通过特殊的方式建立联系，这种特殊的方式叫做目录项（directory entry 或 dentry）。目录文件（Linux 一切皆文件，目录也不例外）通过若干目录项记录着该目录下所有文件的信息。每个目录项由两部分组成：所包含文件的文件名，以及该文件名对应的 inode 号。目录项建立文件名与 inode 对应关系，从而实现「文件名 –&gt; inode –&gt; 数据块」的访问流程：\n\n硬链接所谓硬链接，就是上图第一个箭头，即文件名到 inode 的链接（目录项）。\nLinux 下所有文件默认都会有一个硬链接，用来生成文件名（文件至少要有一个硬链接才能访问其内容）：\n\n硬链接的创建使用 ln 或 ln -P 命令创建一个硬链接，格式 ln [-P] 源文件 目标文件。下面为 test.txt 文件创建一个硬链接 test-hd.txt：\n\n可以看到两个文件的文件的类型、大小一致，重点在于 inode 号是相同的,创建链接后两个文件的链接数变为 2，表示可以通过 2 个名字都访问到同一个 inode 下相同的数据块\n软连接（Linux 中的「快捷方式」）软链接（soft link）又称符号链接（symbolic link 或 symlink），软链接与硬链接不同，若文件用户的数据块中存放的内容是另一文件的路径名的文本指向，则该文件就是软连接。\n将内容写进符号链接里，那这些内容也会同样写入引用文件。而当删除一个符号链接的时候，删除的只是符号链接而没有删除文件本身。而如果先删除了文件，该链接依旧存在，却不会指向任何文件。但是你打开该链接，就会报错“NO such file or directory”\n软链接的创建使用 ln -s 命令创建一个软链接，格式 ln -s 源文件 目标文件。下面为 test.txt 文件创建一个软链接 test-soft.txt：\n\n两个文件的类型、大小一目了然，inode 号不同说明这是两个不同的文件，创建软链接并不会增加文件的链接数（上图命令行中所有文件链接数均为 1），软链接并不会直接访问 inode，仅仅指向目标数据的文件名。\n软硬区别1.硬链接不能引用自身文件系统之外的文件。也就是说，链接不能引用与该链接不在同一磁盘分区的文件。\n2.硬链接不能引用目录。软链接即可以是文件也可以是目录。\n","slug":"linux/软链接&硬链接","date":"2021-03-15T10:32:47.000Z","categories_index":"学习记录","tags_index":"Linux","author_index":"Polnareff"},{"id":"6d776fe044c383329f434d8d6568a06a","title":"Pulsar简介","content":"Pulsar简介Apache Pulsar 是灵活的发布-订阅消息系统（Flexible Pub/Sub messaging），采用分层分片架构。\n特性：\n\n线性扩展。能够丝滑的扩容到成百上千个节点(Kafka扩容需要占用很多系统资源在节点间拷贝数据，而Plusar完全不用)\n高吞吐。已经在Yahoo的生产环境中经受了考验，每秒数百万消息\n低延迟。在大规模的消息量下依然能够保持低延迟(&lt; 5ms)\n持久化机制。Plusar的持久化机制构建在Apache BookKeeper之上，提供了写与读之间的IO隔离\n基于地理位置的复制。Plusar将多地域/可用区的复制作为首要特性支持。用户只需配置好可用区，消息就会被源源不断的复制到其他可用区。当某一个可用区挂掉或者发生网络分区，plusar会在之后不断的重试。\n部署方式的多样化。既可以运行在裸机，也支持目前例如Docker、K8S的一些容器化方案以及不同的云厂商，同时在本地开发时也只需要一行命令即可启动整个环境。\nTopic支持多种消费模式:exclusive、shared、failover、key_shared\n\n架构概述\nPulsar采用“存储和服务分离”的两层架构：\n\nBroker：负责处理和负载均衡 producer 发出的消息，并将这些消息分派给 consumer\nPulsar的broker是一个无状态组件\n一个HTTP服务器，它为生产者和使用者公开用于管理任务和主题查找的REST API。生产者连接到代理以发布消息，而消费者连接到代理以使用消息\n一个调度分发器, 它是异步的TCP服务器，通过自定义 二进制协议应用于所有相关的数据传输\n\n\nBookKeeper：负责消息的持久化存储，多个组成Bookie的 集群\n一个分布式的预写日志（WAL）系统\n能让Pulsar创建多个独立的日志，这种独立的日志就是ledgers. 随着时间的推移，Pulsar会为Topic创建多个ledgers\n保证了多系统挂掉时ledgers的读取一致性\n提供不同的Bookies之间均匀的IO分布的特性\n除了消息数据，cursors（消费端订阅消费的位置）也会被持久化入BookKeeper\n\n\n\nLedgersledger是一个只追加的数据结构，并且只有一个写入器，这个写入器负责多个BookKeeper存储节点（就是Bookies）的写入。 Ledger的条目会被复制到多个bookies，Pulsar Broker可以创建ledeger，添加内容到ledger和关闭ledger。\n\nopenLedger(5,3,2)\n5:代表选取五个Bookie节点来记录数据\n3:节点中有多少份备份(write quorum)，同步写\n2:几个节点备份成功算写成功(ack quorum)，假如有读取请求也只会读取ack quorum中的bookie\npulsar中默认为(2,2,2)\n\n\n\nJournal WAL（WAL 机制的原理也很简单：修改并不直接写入到数据库文件中，而是写入到另外一个称为WAL 的文件中）\n概念：数据先入Journal Disks，保障这个盘的IOPS有助提高性能\n清理：当 Write Cache 完成 Flush 落盘后自动删除。\n\n\nEntry Logs\n概念：真正落盘的日志文件，有序保存不同 ledger 的 entries。\n清理：bookie 后台 GC 线程定期检查其关联的 ledgers 是否在 zk 上已删除，若已删除则自动清理。\n\n\nIndex Files\n概念：高效顺序写的副作用是，必须在外围维护 (ledger_id, entry_id) 到 Entry_Log 的映射索引，才能实现高效读，故 Flush Cache 时会分离出索引文件。\n\n\n\n容错&amp;扩容Broker挂掉后：\n\n把对应的ownership挂在到一个可用的broker上\n其实就是对应zk的节点数据变更\n客户端可能存在一次超时重试\n\n\nBookKeeper无需任何变动\n\nBookie挂掉后：由于有segment分片副本\n\n做到了应用无感知\n数据恢复可控（调节健康检查频率、数据恢复的带宽等）\n\n扩容：解决了 Kafka 手工扩容、故障恢复慢的问题。\n\n稳定性可用性高：秒级故障恢复\n水平线性扩容：存储与计算分离，对 Broker 扩容提升读写吞吐，对 Bookie 扩容降低集群负载并提升存储容量。\n扩容负载均衡：Bookie 扩容后新的 ledger 会在新 Bookie 上创建，自动均摊负载。\n\n","slug":"mq/pulsar","date":"2021-03-15T10:32:47.000Z","categories_index":"学习记录","tags_index":"Pulsar","author_index":"Polnareff"},{"id":"33585b12afe7c2c9a6e009942104d7e9","title":"Java内存模型","content":"简介内存模型描述了程序中各个变量（实例域、静态域和数组元素）之间的关系，以及在实际计算机系统中将变量存储到内存和从内存中取出变量这样的底层细节，对象最终是存储在内存里面的，这点没有错，但是编译器、运行库、处理器或者系统缓存可以有特权在变量指定内存位置存储或者取出变量的值。\n【JMM】（Java Memory Model的缩写）允许编译器和缓存以数据在处理器特定的缓存（或寄存器）和主存之间移动的次序拥有重要的特权，除非程序员使用了volatile或synchronized明确请求了某些可见性的保证。\n\n\n程序会表现出出人意料的行为Java 的语义允许编译器和微处理器进行优化，这会影响到未正确同步的代码，可能 会使它们的行为看起来自相矛盾。\n例子1：\n\n程序中用到了局部变量 r1 和 r2，以及共享变量 A 和 B。可能 会出现 r2 == 2、r1 == 1 这样的结果。直觉上，应当要么指令 1 先执行要么指令 3 先执行。如果指令 1 先执行，它不应该能看到指令 4 中写入的值。如果指令 3 先执 行，它不应该能看到指令 2 写的值。\n这段代码没有被充分同步：\n\n一个线程里有个写操作\n另一个线程读取了这个写入的变量值\n且读写操作没有被同步排序\n\n当上述情况发生时，称之为存在数据争用（data race），有几种机制都可以产生图 1 中的重排序。JIT 编译器和处理器可以对代码进行重新 整理。此外，运行 JVM 的机器的分级存储系统可以使代码看起来像被重排序过。\n例子2：\n\n一种常规的编译器优化会在使用 r5 的时候重用 r2：它们读取的都是 r1.x 且它们之 间没有写 r1.x 的操作。\n在线程 1 第一次读取 r1.x 与读取 r3.x 之间，线程 2 对 r6.x 进行了赋值。如果编译器决定在 r5 处重用 r2 的值，那么 r2 和 r5 的值都是 0，r4 的值是 3.从编程人员的角度来看，p.x 的值从 0 变为 3 后又变回了 0。\n理解一个程序是否被正确的同步了，有两个关键概念：冲突访问（对同一个共享字段或数组元素存在两个访问（读 或写），且至少有一个访问是写操作，就称作有冲突）和Happens-Before\nHappens-Before两个动作（action）可以被 happens-before 关系排序。如果一 个动作 happens-before 另一个动作，则第一个对第二个可见，且第一个排在第二个之前。\nhappens-before 规则：\n\n某个线程中的每个动作都 happens-before 该线程中该动作后面的动作。\n某个管程上的 unlock 动作 happens-before 同一个管程上后续的 lock 动作。\n对某个volatile 字段的写操作 happens-before 每个后续对该 volatile 字段的读 操作。 \n在某个线程对象上调用 start()方法 happens-before 该启动了的线程中的任意 动作。\n某个线程中的所有动作 happens-before 任意其它线程成功从该线程对象上的 join()中返回。\n如果某个动作 a happens-before 动作 b，且 b happens-before 动作 c，则有 a happens-before c.\n\n顺序一致性\n顺序一致性是程序执行过程中可见性和顺序的强有力保证。在顺序一致的执行过程 中，所有动作（如读和写）间存在一个全序关系，与程序的顺序一致。每个动作都是原子的且立即对所有线程可见。如果一个程序没有数据争用，那么该 程序的执行看起来将是顺序一致的。如果将顺序一致性作为内存模型，之前讨论的一些编译器和处理器优化将不再合法。\nfinal 字段\nfinal 字段也允许编程人员在不需要同步的情况下实现线程安全的不可变对象。一个线程安全的不可变对象被所有线程都视为不可变的，即使不可变对象的引用在线程间传递时存在数据争用。这提供了安全保证，可以防止不正确或恶意代码误用了不可变类。\nsynchronizes-with简单来说，synchronizes-with关系是用来确保happen-before关系的，即发生在不同线程间的同步关系，A synchronized B时，表示如果A先于B执行，那么A的执行结果对B一定可见。\n包括：\n\n某个管程 m 上的解锁动作 synchronizes-with 所有后续在 m 上的锁定动作 。 \n对 volatile 变量 v 的写操作 synchronizes-with 所有后续任意线程对 v 的读操作。\n用于启动一个线程的动作 synchronizes-with 该新启动线程中的第一个动作。线程 T1 的最后一个动作 synchronizes-with 线程 T2 中任一用于探测 T1 是否终止的动作。T2 可能通过调用 T1.isAlive()或者在 T1 上执行一个 join 动作来达到这个目的。\n如果线程 T1 中断了线程 T2，T1 的中断操作 synchronizes-with 任意时刻任 何其它线程（包括 T2）用于确定 T2 是否被中断的操作。这可以通过抛出 一个 InterruptedException 或调用 Thread.interrupted 与 Thread.isInterrupted 来实现。\n为每个变量写默认值（0，false 或 null）的动作 synchronizes-with 每个线程 中的第一个动作。\n调用对象的终结方法时，会隐式的读取该对象的引用。\n\nJava 内存模型的近似模型顺序一致的内存模型它太严格了，不适合做 Java 内存模型，因为它 禁止了标准的编译器和处理器优化。\nHappens-Before 内存模型 happens-before 内存模型，这个模型已经非常接近 Java内存模型的需求，但是，它太弱了；其允许违反因果关系这种不可接受的事情发生。\nJava 内存模型的正式规范\n动作与执行过程\n外部动作\n线程分散（thread divergence）动作\n定义\nsynchronizes-with 的定义\nhappens-before 的定义\n充分的同步边缘（suffcient synchronization edges）的定义\n偏序和函数的限制（ Restrictions of partial orders and functions）\n\n\n\n\n良构的（ Well-Formed）执行过程\n.每个对变量 x 的读都能看到一个对 x 的写\n同步顺序与程序顺序以及互斥是一致的\n线程的运行遵守线程内（intra-thread）一致性\n线程的运行遵守同步顺序一致性\n线程的运行遵守 happens-before 一致性\n\n\n执行过程的因果（Causality）要求\n可观察的行为与不会终止的执行过程\n\n8种原子操作\nlock:将一个变量标识为被一个线程独占状态\nunclock:将一个变量从独占状态释放出来，释放后的变量才可以被其他线程锁定\nread:将一个变量的值从主内存传输到工作内存中，以便随后的load操作\nload:把read操作从主内存中得到的变量值放入工作内存的变量的副本中\nuse:把工作内存中的一个变量的值传给执行引擎，每当虚拟机遇到一个使用到变量的指令时都会使用该指令\nassign:把一个从执行引擎接收到的值赋给工作内存中的变量，每当虚拟机遇到一个给变量赋值的指令时，都要使用该操作\nstore:把工作内存中的一个变量的值传递给主内存，以便随后的write操作\nwrite:把store操作从工作内存中得到的变量的值写到主内存中的变量\n\n为什么对long的操作不是原子的？某些 JavaTM 实现可能发现将对 64 位 long 或 double 值的写操作分成两次相邻的 32 位值写操作更方便。\n在64位的环境下，long和double的读写都是是原子操作。\n","slug":"java/jmm","date":"2021-03-09T10:32:47.000Z","categories_index":"学习记录","tags_index":"Java","author_index":"Polnareff"},{"id":"0602fa7501a658e7531a856a02eb9d8f","title":"Kafka简介","content":"架构\n\nBroker：消息中间件处理结点，一个Kafka节点就是一个broker，多个broker可以组成一个Kafka集群\nTopic：一类消息，Kafka集群能够同时负责多个topic的分发\nPartition：topic物理上的分组，一个topic可以分为多个partition，每个partition是一个有序的队列\nSegment：partition物理上由多个segment组成\noffset：每个partition都由一系列有序的、不可变的消息组成，这些消息被连续的追加到partition中\nConsumer：消息消费者，向Kafka broker读取消息的客户端\nConsumer Group：每个Consumer属于一个特定的Consumer Group\n\nKafka消息存储格式在Kafka文件存储中，同一个topic下有多个不同partition，每个partition为一个目录，partiton命名规则为topic名称+有序序号，第一个partiton序号从0开始，序号最大值为partitions数量减1\n\n\n每个partion（目录）相当于一个巨型文件被平均分配到多个大小相等segment（段）数据文件中\n每个partiton只需要支持顺序读写就行了，segment文件生命周期由服务端配置参数决定\n\nsegment\nsegment file组成：由2大部分组成，分别为index file和data file，此2个文件一一对应，成对出现，后缀”.index”和“.log”分别表示为segment索引文件、数据文件\nsegment文件命名规则：partion全局的第一个segment从0开始，后续每个segment文件名为上一个segment文件最后一条消息的offset值。数值最大为64位long大小，19位数字字符长度，没有数字用0填充\n\n\n索引文件存储大量元数据，数据文件存储大量消息，索引文件中元数据指向对应数据文件中message的物理偏移地址\n\n其中以索引文件中元数据3,497为例，依次在数据文件中表示第3个message（在全局partiton表示第368772个message），以及该消息的物理偏移地址为497\n\n\noffset：每条消息的有序的id号\nCRC32：用crc32校验message\nmagic：Kafka服务程序协议版本号\nattributes：独立版本、或标识压缩类型、或编码类型\nvalue bytes payload：表示实际消息数据\n\n副本（replication）策略1.数据同步同一个Partition可能会有多个Replica，而这时需要在这些Replication之间选出一个Leader，Producer和Consumer只与这个Leader交互，其它Replica作为Follower从Leader中复制数据\n2.副本放置策略\n将所有存活的N个Brokers和待分配的Partition排序\n将第i个Partition分配到第(i mod n)个Broker上，这个Partition的第一个Replica存在于这个分配的Broker上，并且会作为partition的优先副本\n将第i个Partition的第j个Replica分配到第((i + j) mod n)个Broker上\n\n3.同步策略\nProducer在发布消息到某个Partition的Leader\nProducer只将该消息发送到该Partition的Leader，该消息写入其本地Log\n每个Follower都从Leader pull数据同步\nFollower在收到该消息先向Leader发送ACK再写入其Log后（Kafka只能保证它被存于多个Replica的内存中，而不能保证它们被持久化到磁盘中，也就不能完全保证异常发生后该条消息一定能被Consumer消费）\nkafka维护了一个ISR（in-sync replicas ），如果一个follower宕机（broker宕机当然算），或者落后太多，leader将把它从”in sync” list中移除\n\n\n\n4.leader选举kafka0.8.2之前：\n为Partition分配副本，指定一个ZNode临时节点，第一个成功创建节点的副本就是Leader节点，其他副本会在这个ZNode节点上注册Watcher监听器，一旦Leader宕机，对应的临时节点就会被自动删除，这时注册在该节点上的所有Follower都会收到监听器事件，它们都会尝试创建该节点，只有创建成功的那个follower才会成为Leader\n之后：\n\n整个集群中选举出一个Broker作为Controller\nController为所有Topic的所有Partition指定Leader及Follower\n当一个leader宕机，kafka Controller从分区的ISR中选一个作为leader\n\n高吞吐量的几点设计\n顺序写入\n\nPage Cache\n\n零拷贝技术\n\n引入了Partition以及优秀的文件存储\n\nProducer向broker push消息，Consumer从broker pull消息\n\n\n","slug":"mq/Kafka","date":"2021-03-01T10:32:47.000Z","categories_index":"学习记录","tags_index":"Kafka","author_index":"Polnareff"},{"id":"f1f87b7aa7ff4eb8772e03523d7680ea","title":"Trojan搭建","content":"Trojan搭建服务端前期准备\n系统centos7 /debian9 /ubuntu16以上\n域名解析到VPS并生效\n\n一键脚本代码此脚本感谢 atrandys\nGithub项目地址：https://github.com/atrandys/trojan\n安装好curl，若是有此环境，请跳过\napt-get update -y &amp;&amp; apt-get install curl -y    ##Ubuntu&#x2F;Debian 系统安装 Curl 方法\nyum update -y &amp;&amp; yum install curl -y            ##Centos 系统安装 Curl 方法\n\n有些VPS需要安装 XZ 压缩工具\napt-get install xz-utils   #Debian&#x2F;Ubuntu安装 XZ 压缩工具命令\nyum install xz    #CentOS安装 XZ 压缩工具\n\nTrojan一键脚本代码：\nbash &lt;(curl -s -L https:&#x2F;&#x2F;github.com&#x2F;V2RaySSR&#x2F;Trojan&#x2F;raw&#x2F;master&#x2F;Trojan.sh)\n\n\n先1安装trojan，再2安装想要的加速模块：\n\n查看bbr是否开启\nlsmod | grep bbr\n\n未开启手动开启bbr\necho &quot;net.ipv4.tcp_congestion_control&#x3D;bbr&quot; &gt;&gt; &#x2F;etc&#x2F;sysctl.conf\n\n服务端怎么修改密码trojan服务端配置文件路径如下，如需修改内容，修改以下文件即可\n&#x2F;usr&#x2F;src&#x2F;trojan&#x2F;server.conf\n\n修改完成后，重启trojan服务端即可，同时客户端的密码也要同步修改哦\nsystemctl restart trojan\n\n客户端（clash）github：https://github.com/yichengchen/clashX\nwindows客户端的下载：https://github.com/Fndroid/clash_for_windows_pkg/releases\n安卓平台客户端下载：https://github.com/Kr328/ClashForAndroid/releases\n配置模板：https://raw.githubusercontent.com/JeannieStudio/all_install/master/clash-template.yaml\n模版下载好后，修改你的域名和密码即可\n\n","slug":"vps/Trojan一键安装脚本","date":"2021-02-20T10:32:47.000Z","categories_index":"教程","tags_index":"vps","author_index":"Polnareff"},{"id":"ea4f29ef076f8fcb5cf3c8e4ef9a996f","title":"ZooKeeper：分布式协调服务","content":"ZooKeeper：分布式协调服务统一命名服务、状态同步服务、集群管理、分布式应用配置项的管理等。\nZooKeeper提供的名称空间与标准文件系统的名称空间非常相似\n\n其中每个节点称为znode\n\n持久节点\n临时节点\n会话关闭消失\n\n\n顺序节点\nzk都会在路径后面自动添加上10位的数字\n\n\n\n节点信息对应\ncZxid            创建节点时的事务id   \nctime            创建节点的时\nmZxid            更新节点时的事务id(如未做修改，创建事务的id和更新事务的id是一样的)\nmtime            修改节点的时间\npZxid            当前节点下的子节点列表里面，最后一次被修改的时候的事务id (只有子节点变更以后，pZxid才会变化)\ncversion         当前节点的子节点版本号\ndataVersion      当前数据内容的版本号(修改内容会变)\naclVersion       当前节点acl(权限）变更的版本号\nephemeralOwner   会话信息(会话信息，创建临时节点才会有的。当前客户端连接到ZooKeeper服务，会产生一个会话，会话和服务端建立后，会产生一个标志。基于这个标志，才能知道当前会话结束后，应该把哪些节点删除。是当前会话的一个标志)\ndataLength       当前节点内容的长度 \nnumChildren      子节点的数量 \n\nZooKeeper Watcheswatch事件是一次触发，发送给设置了watch的客户端，该事件在设置watch的数据发生更改时发生，特性：\n\n数据更改后一次性触发（触发后就移除）\n3.6.0后可以设置永久的，递归的watch，在被触发时不会被删除，并且会以递归方式触发已注册znode以及所有子znode的更改\n\n\n客户端串行执行\nwatcher回调的过程是一个串行同步的过程，这为我们保证了顺序\n\n\n轻量级设计\nWatcherEvent是Zookeeper整个Watcher通知机制的最小通知单元。整个单元结构只包含三部分：通知状态，事件类型和节点路径。事件的具体内容需要客户端主动获取\n\n\n\n注册通知流程图：\n\nWatchManager类客户端在向 ZooKeeper 服务器注册 Watcher 的同时，会将 Watcher 对象存储在客户端的 WatchManager 中，事件触发后，会向客户端发送通知，客户端线程从 WatchManager 中取出对应的 Watcher 对象来执行回调逻辑\nprivate final HashMap&lt;String, HashSet&lt;Watcher&gt;&gt; watchTable &#x3D;\n new HashMap&lt;String, HashSet&lt;Watcher&gt;&gt;();\npublic synchronized void addWatch(String path, Watcher watcher) &#123;\n HashSet&lt;Watcher&gt; list &#x3D; watchTable.get(path);\n if (list &#x3D;&#x3D; null) &#123;\n &#x2F;&#x2F; don&#39;t waste memory if there are few watches on a node\n &#x2F;&#x2F; rehash when the 4th entry is added, doubling size thereafter\n &#x2F;&#x2F; seems like a good compromise\n list &#x3D; new HashSet&lt;Watcher&gt;(4);\n watchTable.put(path, list);\n &#125;\n list.add(watcher);\n\n HashSet&lt;String&gt; paths &#x3D; watch2Paths.get(watcher);\n if (paths &#x3D;&#x3D; null) &#123;\n &#x2F;&#x2F; cnxns typically have many watches, so use default cap here\n paths &#x3D; new HashSet&lt;String&gt;();\n watch2Paths.put(watcher, paths);\n &#125;\n paths.add(path);\n&#125;\n\nWatcher 接口process 方法是 Watcher 接口中的一个回调方法，当 ZooKeeper 向客户端发送一个 Watcher 事件通知时，客户端就会对相应的 process 方法进行回调，从而实现对事件的处理。\npublic interface Watcher &#123;\nabstract public void process(WatchedEvent event);\n&#125;\n&#x2F;&#x2F;WatchedEvent 包含了每一个事件的三个基本属性：通知状态（KeeperState）、事件类型（EventType）和节点路径（Path）\n\nZab（ ZooKeeper Atomic Broadcast）协议原子广播\n\n写请求到leader\nleader会开启事务-&gt;写操作-&gt;生成proposal发给所有的follower的FIFO队列\nfollower接收到proposal-&gt;开启事务-&gt;写操作-&gt;ack\nleader收到ack过半-&gt;提交事务-&gt;发送commit给所有follower\nfollower提交事务\n\n崩溃恢复Zxid：xid 是一个 64 位的数字，其中低 32 位是一个递增的计数器，高32位epoch\nepoch：每次选主后会+1\n恢复选主原则：\n1）Follower具备最高的zxid2）票数过半\n选出leader后，Leader 服务器会根据自己最后被提交的 ZXID 和 Follower 上的 ZXID 进行比对，然后回滚或同步。\n日志同步数据\n\nLeader发送同步日志给Follower，该过程传输的主要是日志数据流或者Leader给Follower的各种命令；\nLeader发送NEWLEADER命令给Follower，该命令的作用应该是告诉Follower日志同步已经完成，Follower对该NEWLEADER作出ACK，而Leader会等待该ACK消息；\nLeader最后发送UPTODATE命令至Follower，这个命令的作用应该是告诉Follower，我已经收到了你的ACK，而Follower这边收到该消息的时候说明一切与Leader同步的初始化工作都已经完成，可以进入正常的处理流程了，而Leader这边发完该命令后也可以进入正常的请求处理流程了。\n\nraft动画演示网站：http://thesecretlivesofdata.com/raft/ \nraft动画演示网站 https://raft.github.io/ \nZooKeeper Internals https://zookeeper.apache.org/doc/r3.5.0-alpha/zookeeperInternals.html \n","slug":"zookeeper/zk","date":"2020-10-05T10:32:47.000Z","categories_index":"学习记录","tags_index":"Zookeeper","author_index":"Polnareff"},{"id":"dd327c2a75c4b810517d5dca0d9f2612","title":"SDS 简单动态字符串","content":"SDS 简单动态字符串（simple dynamic string）Redis 没有直接使用C语言传统的字符串表示，而是自己构建了一种名为简单动态字符串（simple dynamic string SDS）的抽象类型，并将SDS用作Redis 的默认字符串表示。\n\n\nSDS定义struct sdshdr &#123;\n  \n      int len;\n  \n      int free;\n  \n      char buf[];\n&#125;;\n\n\nlen:：表示SDS保存字符串长度\n\nfree：表示SDS还未分配使用的空间\n\nbuf：保存字符串，最后一个保存空字符’\\0’\n\n\nSDS与C字符串区别1.常数复杂度获取字符串长度C 字符串并不记录自身的长度信息， 所以为了获取一个 C 字符串的长度， 程序必须遍历整个字符串复杂度为 O(N) ；\nSDS 在 len 属性中记录了 SDS 本身的长度， 所以获取一个 SDS 长度的复杂度仅为 O(1) 。\n2.杜绝缓冲区溢出 C 字符串不记录自身长度带来的另一个问题是容易造成缓冲区溢出（buffer overflow）\n与 C 字符串不同， SDS 的空间分配策略完全杜绝了发生缓冲区溢出的可能性:当 SDS API 需要对 SDS 进行修改时， API 会先检查 SDS 的空间是否满足修改所需的要求， 如果不满足的话， API 会自动将 SDS 的空间扩展至执行修改所需的大小\n缓冲区溢出假设程序里有两个在内存中紧邻着的 C 字符串 s1 和 s2 ， 其中 s1 保存了字符串 &quot;Redis&quot; ， 而 s2 则保存了字符串 &quot;MongoDB&quot; ， 如图 2-7 所示：\n\n如果一个程序员决定通过执行：\nstrcat(s1, &quot; Cluster&quot;);\n\ns1 的内容修改为 &quot;Redis Cluster&quot; ， 但粗心的他却忘了在执行 strcat 之前为 s1 分配足够的空间， 那么在 strcat 函数执行之后， s1 的数据将溢出到 s2 所在的空间中， 导致 s2 保存的内容被意外地修改， 如图 2-8 所示:\n\n3.减少修改字符串时带来的内存重分配次数每次增长或者缩短一个 C 字符串， 程序都总要对保存这个 C 字符串的数组进行一次内存重分配操作：\n\n如果程序执行的是增长字符串的操作， 比如拼接操作（append）， 那么在执行这个操作之前， 程序需要先通过内存重分配来扩展底层数组的空间大小 —— 如果忘了这一步就会产生缓冲区溢出。\n如果程序执行的是缩短字符串的操作， 比如截断操作（trim）， 那么在执行这个操作之后， 程序需要通过内存重分配来释放字符串不再使用的那部分空间 —— 如果忘了这一步就会产生内存泄漏。\n\n 在 SDS 中， buf 数组的长度不一定就是字符数量加一， 数组里面可以包含未使用的字节， 而这些字节的数量就由 SDS 的 free 属性记录。通过未使用空间， SDS 实现了空间预分配和惰性空间释放两种优化策略。\n空间预分配当 SDS 的 API 对一个 SDS 进行修改， 并且需要对 SDS 进行空间扩展的时候， 程序不仅会为 SDS 分配修改所必须要的空间， 还会为 SDS 分配额外的未使用空间\n\n如果对 SDS 进行修改之后， SDS 的长度为13byte（也即是 len 属性的值）小于 1 MB ， 这时 SDS len 属性的值将和 free 属性的值相同都为13byte。\n如果对 SDS 进行修改之后， SDS 的长度为2 MB大于等于 1 MB ， SDS 的 len 将变成 2 MB ， free分配 1 MB 的未使用空间\n\n惰性空间释放当 SDS 的 API 需要缩短 SDS 保存的字符串时， 程序并不立即使用内存重分配来回收缩短后多出来的字节， 而是使用 free 属性将这些字节的数量记录起来， 并等待将来使用。\nSDS 也提供了相应的 API ， 让我们可以在有需要时， 真正地释放 SDS 里面的未使用空间， 所以不用担心惰性空间释放策略会造成内存浪费。\n4.二进制安全C 字符串中的字符必须符合某种编码（比如 ASCII）， 并且除了字符串的末尾之外， 字符串里面不能包含空字符， 否则最先被程序读入的空字符将被误认为是字符串结尾 —— 这些限制使得 C 字符串只能保存文本数据， 而不能保存像图片、音频、视频、压缩文件这样的二进制数据。\n所有 SDS API 都会以处理二进制的方式来处理 SDS 存放在 buf 数组里的数据， 程序不会对其中的数据做任何限制、过滤、或者假设 —— 数据在写入时是什么样的， 它被读取时就是什么样。\n5.兼容部分 C 字符串函数虽然 SDS 的 API 都是二进制安全的， 但它们一样遵循 C 字符串以空字符结尾的惯例： 这些 API 总会将 SDS 保存的数据的末尾设置为空字符， 并且总会在为 buf 数组分配空间时多分配一个字节来容纳这个空字符， 这是为了让那些保存文本数据的 SDS 可以重用一部分 &lt;string.h&gt; 库定义的函数\nSDS API\n\n\n函数\n作用\n时间复杂度\n\n\n\nsdsnew\n创建一个包含给定 C 字符串的 SDS 。\nO(N) ， N 为给定 C 字符串的长度。\n\n\nsdsempty\n创建一个不包含任何内容的空 SDS 。\nO(1)\n\n\nsdsfree\n释放给定的 SDS 。\nO(1)\n\n\nsdslen\n返回 SDS 的已使用空间字节数。\n这个值可以通过读取 SDS 的 len 属性来直接获得， 复杂度为 O(1) 。\n\n\nsdsavail\n返回 SDS 的未使用空间字节数。\n这个值可以通过读取 SDS 的 free 属性来直接获得， 复杂度为 O(1) 。\n\n\nsdsdup\n创建一个给定 SDS 的副本（copy）。\nO(N) ， N 为给定 SDS 的长度。\n\n\nsdsclear\n清空 SDS 保存的字符串内容。\n因为惰性空间释放策略，复杂度为 O(1) 。\n\n\nsdscat\n将给定 C 字符串拼接到 SDS 字符串的末尾。\nO(N) ， N 为被拼接 C 字符串的长度。\n\n\nsdscatsds\n将给定 SDS 字符串拼接到另一个 SDS 字符串的末尾。\nO(N) ， N 为被拼接 SDS 字符串的长度。\n\n\nsdscpy\n将给定的 C 字符串复制到 SDS 里面， 覆盖 SDS 原有的字符串。\nO(N) ， N 为被复制 C 字符串的长度。\n\n\nsdsgrowzero\n用空字符将 SDS 扩展至给定长度。\nO(N) ， N 为扩展新增的字节数。\n\n\nsdsrange\n保留 SDS 给定区间内的数据， 不在区间内的数据会被覆盖或清除。\nO(N) ， N 为被保留数据的字节数。\n\n\nsdstrim\n接受一个 SDS 和一个 C 字符串作为参数， 从 SDS 左右两端分别移除所有在 C 字符串中出现过的字符。\nO(M*N) ， M 为 SDS 的长度， N 为给定 C 字符串的长度。\n\n\nsdscmp\n对比两个 SDS 字符串是否相同。\nO(N) ， N 为两个 SDS 中较短的那个 SDS 的长度。\n\n\n","slug":"redis/sds","date":"2020-08-12T10:32:47.000Z","categories_index":"学习记录","tags_index":"Redis","author_index":"Polnareff"},{"id":"6199f8896169806e8b51dc181ed51cca","title":"线程池总结","content":"七大参数\ncorePoolSize 线程池核心线程大小\nmaximumPoolSize 线程池最大线程数量\nkeepAliveTime 空闲线程存活时间\nunit 空间线程存活时间单位\nworkQueue 工作队列\nthreadFactory 线程工厂\n创建一个新线程时使用的工厂，可以用来设定线程名、是否为daemon线程等等\n\n\nhandler 拒绝策略\n\n\n\nworkQueue新任务被提交后，会先进入到此工作队列中，任务调度时再从队列中取出任务。jdk中提供了四种工作队列：\n①ArrayBlockingQueue\n基于数组的有界阻塞队列，按FIFO排序。新任务进来后，会放到该队列的队尾，有界的数组可以防止资源耗尽问题。当线程池中线程数量达到corePoolSize后，再有新任务进来，则会将任务放入该队列的队尾，等待被调度。如果队列已经是满的，则创建一个新线程，如果线程数量已经达到maxPoolSize，则会执行拒绝策略。\n②LinkedBlockingQuene\n基于链表的无界阻塞队列（其实最大容量为Interger.MAX），按照FIFO排序。由于该队列的近似无界性，当线程池中线程数量达到corePoolSize后，再有新任务进来，会一直存入该队列，而不会去创建新线程直到maxPoolSize，因此使用该工作队列时，参数maxPoolSize其实是不起作用的。\n③SynchronousQuene\n一个不缓存任务的阻塞队列，生产者放入一个任务必须等到消费者取出这个任务。也就是说新任务进来时，不会缓存，而是直接被调度执行该任务，如果没有可用线程，则创建新线程，如果线程数量达到maxPoolSize，则执行拒绝策略。\n④PriorityBlockingQueue\n具有优先级的无界阻塞队列，优先级通过参数Comparator实现。\nhandler①CallerRunsPolicy\n在调用者线程中直接执行被拒绝任务的run方法，除非线程池已经shutdown，则直接抛弃任务。\n②AbortPolicy\n直接丢弃任务，并抛出RejectedExecutionException异常。\n ③DiscardPolicy\n直接丢弃任务，什么都不做。\n④DiscardOldestPolicy\n抛弃进入队列最早的那个任务，然后尝试把这次拒绝的任务放入队列\n实现 RejectedExecutionHandler 接口扩展netty自己实现的线程池里面私有的一个拒绝策略。单独启动一个新的临时线程来执行任务。\nprivate static final class NewThreadRunsPolicy implements RejectedExecutionHandler &#123;\n        public void rejectedExecution(Runnable r, ThreadPoolExecutor executor) &#123;\n            try &#123;\n                final Thread t &#x3D; new Thread(r, &quot;Temporary task executor&quot;);\n                t.start();\n            &#125; catch (Throwable e) &#123;\n                throw new RejectedExecutionException(\n                        &quot;Failed to start a new thread&quot;, e);\n            &#125;\n        &#125;\n    &#125;\n\n个是dubbo的一个例子，它直接继承的 AbortPolicy ，加强了日志输出，并且输出dump文件\npublic class AbortPolicyWithReport extends ThreadPoolExecutor.AbortPolicy &#123;\n\n    @Override\n    public void rejectedExecution(Runnable r, ThreadPoolExecutor e) &#123;\n        String msg &#x3D; String.format(&quot;Thread pool is EXHAUSTED!&quot; +\n                        &quot; Thread Name: %s, Pool Size: %d (active: %d, core: %d, max: %d, largest: %d), Task: %d (completed: %d),&quot; +\n                        &quot; Executor status:(isShutdown:%s, isTerminated:%s, isTerminating:%s), in %s:&#x2F;&#x2F;%s:%d!&quot;,\n                threadName, e.getPoolSize(), e.getActiveCount(), e.getCorePoolSize(), e.getMaximumPoolSize(), e.getLargestPoolSize(),\n                e.getTaskCount(), e.getCompletedTaskCount(), e.isShutdown(), e.isTerminated(), e.isTerminating(),\n                url.getProtocol(), url.getIp(), url.getPort());\n        logger.warn(msg);\n        dumpJStack();\n        throw new RejectedExecutionException(msg);\n    &#125;\n&#125;\n\n四种常见的线程池CachedThreadPoolpublic static ExecutorService newCachedThreadPool() &#123;\n    return new ThreadPoolExecutor(0, Integer.MAX_VALUE,\n                                  60L, TimeUnit.SECONDS,\n                                  new SynchronousQueue&lt;Runnable&gt;());\n&#125;\n\nSecudleThreadPoolpublic ScheduledThreadPoolExecutor(int corePoolSize) &#123;\n    super(corePoolSize, Integer.MAX_VALUE, 0, NANOSECONDS,\n          new DelayedWorkQueue());\n&#125;\n\nSingleThreadPoolpublic static ExecutorService newSingleThreadExecutor() &#123;\n    return new FinalizableDelegatedExecutorService\n        (new ThreadPoolExecutor(1, 1,\n                                0L, TimeUnit.MILLISECONDS,\n                                new LinkedBlockingQueue&lt;Runnable&gt;()));\n&#125;\n\nFixedThreadPoolpublic static ExecutorService newFixedThreadPool(int nThreads) &#123;\n    return new ThreadPoolExecutor(nThreads, nThreads,\n                                  0L, TimeUnit.MILLISECONDS,\n                                  new LinkedBlockingQueue&lt;Runnable&gt;());\n&#125;\n\n线程提交优先级int c &#x3D; ctl.get();\n&#x2F;&#x2F; 小于核心数，核心线程处理\nif (workerCountOf(c) &lt; corePoolSize) &#123;\n    if (addWorker(command, true))\n        return;\n    c &#x3D; ctl.get();\n&#125;\n&#x2F;&#x2F; 大于核心放队列\nif (isRunning(c) &amp;&amp; workQueue.offer(command)) &#123;\n    int recheck &#x3D; ctl.get();\n    if (! isRunning(recheck) &amp;&amp; remove(command))\n        reject(command);\n    else if (workerCountOf(recheck) &#x3D;&#x3D; 0)\n        addWorker(null, false);\n&#125;\n&#x2F;&#x2F;核心数队列满 非核心线程\nelse if (!addWorker(command, false))\n\t\t&#x2F;&#x2F; 拒绝策略\n    reject(command);\n\nexecute&amp;submit区别public Future&lt;?&gt; submit(Runnable task) &#123;\n    if (task &#x3D;&#x3D; null) throw new NullPointerException();\n    RunnableFuture&lt;Void&gt; ftask &#x3D; newTaskFor(task, null);\n    execute(ftask);\n    return ftask;\n&#125;\n\n\nexecute和submit都属于线程池的方法，execute只能提交Runnable类型的任务，而submit既能提交Runnable类型任务也能提交Callable类型任务。\nexecute会直接抛出任务执行时的异常，submit会吃掉异常，可通过Future的get方法将任务执行时的异常重新抛出。\nexecute所属顶层接口是Executor,submit所属顶层接口是ExecutorService，实现类ThreadPoolExecutor重写了execute方法,抽象类AbstractExecutorService重写了submit方法。\nsubmit也是调用的excute\n\nexecute流程\n\n","slug":"java/threadpool","date":"2020-06-29T10:32:47.000Z","categories_index":"学习记录","tags_index":"Java","author_index":"Polnareff"},{"id":"238fe05c72e7ef06b8187b847de369e2","title":"网络学习记录","content":"OSI层参考模型&amp;TCP/IP参考模型\n\n\n\n\n\n\n\n\nIP\n\n4位版本：0x4指IPv4\n4位首部长度（5-15）：指明IPv4协议包头长度的字节数包含多少个32位，IPv4包头的最小长度是20个字节，最长为60个字节。\n服务类型：前3位优先权字段包的重要性，最后1位未用位必须为0\n中间四位 （分别代表最小延时、最大吞吐量、最高可靠性、最小费用）\n\n\n16位总长度：ip包的总长度单位字节\n16位标识：由上一层来决定（udp、tcp），ip封包重组\n3位标志：df｜mf｜没用\ndf：不分段丢包\nmf：更多分段，0该封包是最後一个封包,1其後还有被分割的封包｡\n\n\n13位分段偏移：封包进行分段的时候会为各片段做好定位记录,以便在重组的时候就能够对号入座｡\n8位生存时间（ttl）：一旦经过一个处理它的路由器,它的值就减去1｡当该字段的值为0时,数据报就被丢弃,并发送ICMP消息通知源主机｡可以预防环路\n8位协议：\n01：icmp\n06：tcp\n17：udp\n\n\n16位首部校验和：首部检验和字段是根据IP首部计算的检验和码,不对首部后面的数据进行计算｡\n\nARPARP协议是“Address Resolution Protocol”（地址解析协议）的缩写。其作用是在以太网环境中，数据的传输所依懒的是MAC地址而非IP地址，而将已知IP地址转换为MAC地址的工作是由ARP协议来完成的。\nhttps://blog.csdn.net/jiejiemcu/article/details/88406088\nhttps://www.cnblogs.com/csguo/p/7527303.html\nARP请求是广播，响应时单播\nARP分组格式\nICMP在RFC，将ICMP 大致分成两种功能：差错通知和信息查询。\nhttps://www.cnblogs.com/iiiiher/p/8513748.html\nTCP\n32位序号：seq\n32位确认序号：ack\n4位首部长度：4位包括TCP头大小，指示何处数据开始。\n保留（6位）：6位值域，这些位必须是0。为了将来定义新的用途而保留。\n标志：6位标志域。表示为：紧急标志、有意义的应答标志、推、重置连接标志、同步序列号标志、完成发送数据标志。按照顺序排列是：URG、ACK、PSH、RST、SYN、FIN。\n16位窗口大小：用来表示想收到的每个TCP数据段的大小。TCP的流量控制由连接的每一端通过声明的窗口大小来提供。窗口大小为字节数，起始于确认序号字段指明的值，这个值是接收端正期望接收的字节。窗口大小是一个16字节字段，因而窗口大小最大为65535字节。\n16位校验和：16位TCP头。源机器基于数据内容计算一个数值，收信息机要与源机器数值 结果完全一样，从而证明数据的有效性。检验和覆盖了整个的TCP报文段：这是一个强制性的字段，一定是由发送端计算和存储，并由接收端进行验证的。\n16位紧急指针：指向后面是优先数据的字节，在URG标志设置了时才有效。如果URG标志没有被设置，紧急域作为填充。加快处理标示为紧急的数据段。\n三次握手\nSYN攻击在三次握手过程中，Server发送SYN-ACK之后，收到Client的ACK之前的TCP连接称为半连接（half-open connect），此时Server处于SYN_RCVD状态，当收到ACK后，Server转入ESTABLISHED状态。SYN攻击就是Client在短时间内伪造大量不存在的IP地址，并向Server不断地发送SYN包，Server回复确认包，并等待Client的确认，由于源地址是不存在的，因此，Server需要不断重发直至超时，这些伪造的SYN包将产时间占用未连接队列，导致正常的SYN请求因为队列满而被丢弃，从而引起网络堵塞甚至系统瘫痪。SYN攻击时一种典型的DDOS攻击。\nTCP四次挥手\n为什么四次挥手？TCP是一个全双工协议，必须单独拆除每一条信道，确保数据能够完成传输；\n当收到对方的FIN报文通知时，它仅仅表示对方没有数据发送给你了；但未必你所有的数据都全部发送给对方了。\n为什么TIME_WAIT状态需要经过2MSL(最大报文段生存时间)才能返回到CLOSE状态？原因有二： 一、保证TCP协议的全双工连接能够可靠关闭 二、保证这次连接的重复数据段从网络中消失\n先说第一点，如果Client直接CLOSED了，那么由于IP协议的不可靠性或者是其它网络原因，导致Server没有收到Client最后回复的ACK。那么Server就会在超时之后继续发送FIN，此时由于Client已经CLOSED了，就找不到与重发的FIN对应的连接，最后Server就会收到RST而不是ACK，Server就会以为是连接错误把问题报告给高层。这样的情况虽然不会造成数据丢失，但是却导致TCP协议不符合可靠连接的要求。所以，Client不是直接进入CLOSED，而是要保持TIME_WAIT，当再次收到FIN的时候，能够保证对方收到ACK，最后正确的关闭连接。\n再说第二点，如果Client直接CLOSED，然后又再向Server发起一个新连接，我们不能保证这个新连接与刚关闭的连接的端口号是不同的。也就是说有可能新连接和老连接的端口号是相同的。一般来说不会发生什么问题，但是还是有特殊情况出现：假设新连接和已经关闭的老连接端口号是一样的，如果前一次连接的某些数据仍然滞留在网络中，这些延迟数据在建立新连接之后才到达Server，由于新连接和老连接的端口号是一样的，又因为TCP协议判断不同连接的依据是socket pair，于是，TCP协议就认为那个延迟的数据是属于新连接的，这样就和真正的新连接的数据包发生混淆了。所以TCP连接还要在TIME_WAIT状态等待2倍MSL，这样可以保证本次连接的所有数据都从网络中消失。\n超时和重传\nTCP使用四种定时器（Timer，也称为“计时器”）：\n重传计时器：Retransmission Timer\n重传时间=2*RTT（往返时延）；\n\n\n坚持计时器：Persistent Timer\n保活计时器：Keeplive Timer\n超时通常设置2小时，若服务器超过2小时还没有收到来自客户的信息，就发送探测报文段，若发送了10个探测报文段（每75秒发送一个）还没收到响应，则终止连接。\n\n\n时间等待计时（2MSL）器：Time_Wait Timer\n\n\n\n","slug":"network/netbase","date":"2020-06-13T10:32:47.000Z","categories_index":"学习记录","tags_index":"Network","author_index":"Polnareff"},{"id":"aa78a5b1d7c1c5eaa46eb8f528b149b8","title":"Stream流中flatMap","content":"Stream流中flatMapflatMap操作的作用是对流的元素进行一对多转换，然后将生成的元素展平到新的流中。\n&#x2F;&#x2F; 假如我们想把ll打平到一个List&lt;String&gt;中？\nList&lt;List&lt;String&gt;&gt; ll &#x3D; Arrays.asList(\n        Arrays.asList(&quot;Virat&quot;, &quot;Dhoni&quot;, &quot;Jadeja&quot;),\n        Arrays.asList(&quot;Warner&quot;, &quot;Watson&quot;, &quot;Smith&quot;),\n        Arrays.asList(&quot;Alex&quot;, &quot;Bell&quot;, &quot;Broad&quot;),\n        Arrays.asList(&quot;Kane&quot;, &quot;Nathan&quot;, &quot;Vettori&quot;),\n        Arrays.asList(&quot;AB&quot;, &quot;Amla&quot;, &quot;Faf&quot;),\n        Arrays.asList(&quot;Sammy&quot;, &quot;Gayle&quot;, &quot;Narine&quot;),\n        Arrays.asList(&quot;Mahela&quot;, &quot;Sanga&quot;, &quot;Dilshan&quot;),\n        Arrays.asList(&quot;Misbah&quot;, &quot;Afridi&quot;, &quot;Shehzad&quot;)\n);\n\n\n\n&#x2F;&#x2F; 土方法\nList&lt;String&gt; collect &#x3D; new ArrayList&lt;&gt;();\nfor (List&lt;String&gt; strings : ll) &#123;\n    collect.addAll(strings);\n&#125;\n\n&#x2F;&#x2F; flatMap\nList&lt;String&gt; collect &#x3D; ll.stream().flatMap(Collection::stream).collect(Collectors.toList());","slug":"java/flatMap","date":"2020-06-11T10:32:47.000Z","categories_index":"学习记录","tags_index":"Java","author_index":"Polnareff"},{"id":"ceeb145b6b590ef958574de11ee6b4fe","title":"macos开发环境搭建","content":"macos开发环境搭建1.装command line toolsxcode-select –install\n2.homebrew的安装使用2.1 使用国内的镜像源安装&#x2F;bin&#x2F;zsh -c &quot;$(curl -fsSL https:&#x2F;&#x2F;gitee.com&#x2F;cunkai&#x2F;HomebrewCN&#x2F;raw&#x2F;master&#x2F;Homebrew.sh)&quot;\n\n2.2 更换国内镜像源替换brew.git:\ncd &quot;$(brew --repo)&quot;\ngit remote set-url origin https:&#x2F;&#x2F;mirrors.ustc.edu.cn&#x2F;brew.git\n\n替换homebrew-core.git:\ncd &quot;$(brew --repo)&#x2F;Library&#x2F;Taps&#x2F;homebrew&#x2F;homebrew-core&quot;\ngit remote set-url origin https:&#x2F;&#x2F;mirrors.ustc.edu.cn&#x2F;homebrew-core.git\n\n替换homebrew-bottles:\n对于bash用户：\necho &#39;export HOMEBREW_BOTTLE_DOMAIN&#x3D;https:&#x2F;&#x2F;mirrors.ustc.edu.cn&#x2F;homebrew-bottles&#39; &gt;&gt; ~&#x2F;.bash_profile\nsource ~&#x2F;.bash_profile\n对于zsh用户:\necho &#39;export HOMEBREW_BOTTLE_DOMAIN&#x3D;https:&#x2F;&#x2F;mirrors.ustc.edu.cn&#x2F;homebrew-bottles&#39; &gt;&gt; ~&#x2F;.zshrc\nsource ~&#x2F;.zshrc\n\n2.3 安装item2()brew cask install iterm2\n\n2.4 oh-my-zshell安装查看系统的shell \ncat &#x2F;etc&#x2F;shells\n使用zsh\nchsh -s &#x2F;bin&#x2F;zsh\n安装oh-my-zsh\ngit clone git:&#x2F;&#x2F;github.com&#x2F;robbyrussell&#x2F;oh-my-zsh.git ~&#x2F;.oh-my-zsh\ncp ~&#x2F;.oh-my-zsh&#x2F;templates&#x2F;zshrc.zsh-template ~&#x2F;.zshrc\n将ZSH_THEME改成ys\nvim ~&#x2F;.zshrc\nZSH_THEME&#x3D;&quot;ys&quot;\nsource ~&#x2F;.zshrc\n安装自动补全插件\ncd ~&#x2F;.oh-my-zsh&#x2F;custom&#x2F;plugins&#x2F;\ngit clone https:&#x2F;&#x2F;github.com&#x2F;zsh-users&#x2F;zsh-autosuggestions\nvi ~&#x2F;.zshrc\n\n3 开发环境搭建3.1 安装javabrew cask install adoptopenjdk\nbrew tap AdoptOpenJDK&#x2F;openjdk\nbrew cask install adoptopenjdk8\nbrew cask install adoptopenjdk9\n\n3.2 安装ideabrew cask install intellij-idea\n激活\nhttps:&#x2F;&#x2F;www.cnblogs.com&#x2F;zero-clown&#x2F;p&#x2F;12775930.html\n\n3.3 安装chromebrew cask install google-chrome\n\n3.4 安装nodebrew install node\n加速cnpm\nnpm install -g cnpm --registry&#x3D;https:&#x2F;&#x2F;registry.npm.taobao.org\nCommitizen是一个撰写合格 Commit message 的工具。\ncnpm install -g commitizen\n生成 package.json 文件 \nnpm init --yes\n使其支持 Angular 的 Commit message 格式。\ncommitizen init cz-conventional-changelog --save --save-exact\n以后，凡是用到git commit命令，一律改为使用git cz\n\n3.5    安装ideabrew cask install intellij-idea\n插件列表\nCodeGlance 代码地图\nTranslation 翻译\nRainbow Brackets 彩虹括号\nGrep Console 日志颜色\nRestfulToolkit 接口查询和测试\nMybatis Log Plugin 收费mybatis sql日志\nFree Mybatis Plugin mapperxml跳转\n\n3.6 安装mysql和navigatebrew install mysql@5.7\n启动\n&#x2F;usr&#x2F;local&#x2F;opt&#x2F;mysql@5.7&#x2F;bin&#x2F;mysql.server start\n安装navigate\nhttps:&#x2F;&#x2F;www.52pojie.cn&#x2F;thread-957406-1-1.html\nRedis-Desktop-Manager\nhttps:&#x2F;&#x2F;blog.csdn.net&#x2F;qq_34156628&#x2F;article&#x2F;details&#x2F;94736663\n\n","slug":"study/macos开发环境搭建","date":"2020-04-22T10:32:47.000Z","categories_index":"教程","tags_index":"MacOS","author_index":"Polnareff"},{"id":"78394d2ce01caa99f662028b4113802c","title":"正则中有特殊字符的问题","content":"正则中有特殊字符的问题String fuzzName &#x3D; &quot;(模糊名称&quot;；  \nPattern pattern &#x3D; Pattern.compile(&quot;^.*&quot; + fuzzName + &quot;.*$&quot;, Pattern.CASE_INSENSITIVE);\n&#x2F;&#x2F; 出现如下错误        \njava.util.regex.PatternSyntaxException: Unclosed group near index \n\n\n\n&#x2F;&#x2F; 解决方式 返回字符串文字模式，元字符或输入序列中的转义序列将没有特殊的含义。\nString brandNameQuote &#x3D; Pattern.quote(fuzzName);\n\n","slug":"question/regex","date":"2020-02-22T10:32:47.000Z","categories_index":"问题记录","tags_index":"RegExp","author_index":"Polnareff"},{"id":"3520b7e6cac833706ed0bae23ac26e48","title":"mysql事务","content":"隔离级别\nREAD UNCOMMITED\n一个事务可以读到其他事务还没提交的数据，会出现脏读\n\n\nREAD COMMITED\n一个事务只能读到另一个事务修改过的数据，并且其他事务修改提交后能查询到最新值，会出现不可重复读、幻读\n\n\nREPEATABLE READ\n一个事务只能读到另一个事务修改过的数据，即使其他事务修改提交后读到的仍是一次的值，会出现幻读\n\n\nSERIALIZABLE\n不允许读写并发操作\n\n\n\n\n\n\n脏读\n脏读就是指当一个事务正在访问数据，并且对数据进行了修改，而这种修改还没有提交到数据库中，这时，另外一个事务也访问这个数据，然后使用了这个数据\n\n\n不可重复读\n是指在一个事务内，多次读同一数据。在这个事务还没有结束时，另外一个事务也访问该同一数据。那么，在第一个事务中的两次读数据之间，由于第二个事务的修改，那么第一个事务两次读到的的数据可能是不一样的。这样就发生了在一个事务内两次读到的数据是不一样的，因此称为是不可重复读。\n\n\n幻读\n是指当事务不是独立执行时发生的一种现象，例如第一个事务对一个表中的数据进行了修改，这种修改涉及到表中的全部数据行。同时，第二个事务也修改这个表中的数据，这种修改是向表中插入一行新数据。那么，以后就会发生操作第一个事务的用户发现表中还有没有修改的数据行，就好象发生了幻觉一样。\n\n\n\nMVCCMVCC在MySQL InnoDB中的实现主要是为了提高数据库并发性能，用更好的方式去处理读-写冲突，做到即使有读写冲突时，也能做到不加锁，非阻塞并发读\n\n读-读：不存在任何问题，也不需要并发控制\n读-写：有线程安全问题，可能会造成事务隔离性问题，可能遇到脏读，幻读，不可重复读\n写-写：有线程安全问题，可能会存在更新丢失问题，比如第一类更新丢失，第二类更新丢失\n\n隐藏字段\nDB_TRX_ID\n6byte，最近修改(修改/插入)事务ID：记录创建这条记录/最后一次修改该记录的事务ID\n\n\nDB_ROLL_PTR\n7byte，回滚指针，指向这条记录的上一个版本（存储于rollback segment里）\n\n\nDB_ROW_ID\n 6byte，隐含的自增ID（隐藏主键），如果数据表没有主键，InnoDB会自动以DB_ROW_ID产生一个聚簇索引\n\n\n实际还有一个删除flag隐藏字段, 既记录被更新或删除并不代表真的删除，而是删除flag变了\n\nundo log\ninsert undo log\n代表事务在insert新记录时产生的undo log, 只在事务回滚时需要，并且在事务提交后可以被立即丢弃\n\n\nupdate undo log\n 事务在进行update或delete时产生的undo log; 不仅在事务回滚时需要，在快照读时也需要；所以不能随便删除，只有在快速读或事务回滚不涉及该日志时，对应的日志才会被purge线程统一清除\n\n\n\npurge\n从前面的分析可以看出，为了实现InnoDB的MVCC机制，更新或者删除操作都只是设置一下老记录的deleted_bit，并不真正将过时的记录删除。\n为了节省磁盘空间，InnoDB有专门的purge线程来清理deleted_bit为true的记录。为了不影响MVCC的正常工作，purge线程自己也维护了一个read view（这个read view相当于系统中最老活跃事务的read view）;如果某个记录的deleted_bit为true，并且DB_TRX_ID相对于purge线程的read view可见，那么这条记录一定是可以被安全清除的。\n\nRead View(读视图)Read View主要是用来做可见性判断的, 即当我们某个事务执行快照读的时候，对该记录创建一个Read View读视图，把它比作条件用来判断当前事务能够看到哪个版本的数据，既可能是当前最新的数据，也有可能是该行记录的undo log里面的某个版本的数据。\nRead View遵循一个可见性算法，主要是将要被修改的数据的最新记录中的DB_TRX_ID（即当前事务ID）取出来，与系统当前其他活跃事务的ID去对比（由Read View维护），如果DB_TRX_ID跟Read View的属性做了某些比较，不符合可见性，那就通过DB_ROLL_PTR回滚指针去取出Undo Log中的DB_TRX_ID再比较，即遍历链表的DB_TRX_ID（从链首到链尾，即从最近的一次修改查起），直到找到满足特定条件的DB_TRX_ID, 那么这个DB_TRX_ID所在的旧记录就是当前事务能看见的最新老版本\n三个全局属性trx_list（名字我随便取的） 一个数值列表，用来维护Read View生成时刻系统正活跃的事务ID up_limit_id 记录trx_list列表中事务ID最小的ID low_limit_id ReadView生成时刻系统尚未分配的下一个事务ID，也就是目前已出现过的事务ID的最大值+1\n\n首先比较DB_TRX_ID &lt; up_limit_id, 如果小于，则当前事务能看到DB_TRX_ID 所在的记录，如果大于等于进入下一个判断\n接下来判断 DB_TRX_ID 大于等于 low_limit_id , 如果大于等于则代表DB_TRX_ID 所在的记录在Read View生成后才出现的，那对当前事务肯定不可见，如果小于则进入下一个判断\n判断DB_TRX_ID 是否在活跃事务之中，trx_list.contains(DB_TRX_ID)，如果在，则代表我Read View生成时刻，你这个事务还在活跃，还没有Commit，你修改的数据，我当前事务也是看不见的；如果不在，则说明，你这个事务在Read View生成之前就已经Commit了，你修改的结果，我当前事务是能看见的\n\n","slug":"mysql/transaction","date":"2020-01-15T10:32:47.000Z","categories_index":"学习记录","tags_index":"Mysql","author_index":"Polnareff"},{"id":"7b902ccdd6fada43c870460978ea59ec","title":"最近看了看mysql锁总结一波","content":"MyISAM表级锁模式：\n表共享读锁 （Table Read Lock）：不会阻塞其他用户对同一表的读请求，但会阻塞对同一表的写请求；\n\n表独占写锁 （Table Write Lock）：会阻塞其他用户对同一表的读和写操作；\n\n\nInnoDB行级锁和表级锁InnoDB锁模式：InnoDB 实现了以下两种类型的行锁：\n\n共享锁（S）：允许一个事务去读一行，阻止其他事务获得相同数据集的排他锁。\n\n排他锁（X）：允许获得排他锁的事务更新数据，阻止其他事务取得相同数据集的共享读锁和排他写锁。\n\n\n为了允许行锁和表锁共存，实现多粒度锁机制，InnoDB 还有两种内部使用的意向锁（Intention Locks），这两种意向锁都是表锁：\n\n意向共享锁（IS）：事务打算给数据行加行共享锁，事务在给一个数据行加共享锁前必须先取得该表的 IS 锁。\n意向排他锁（IX）：事务打算给数据行加行排他锁，事务在给一个数据行加排他锁前必须先取得该表的 IX 锁。\n\n\nInnoDB加锁方法：\n意向锁是 InnoDB 自动加的， 不需用户干预。\n\n对于 UPDATE、 DELETE 和 INSERT 语句， InnoDB会自动给涉及数据集加排他锁（X)；\n\n对于普通 SELECT 语句，InnoDB 不会加任何锁；事务可以通过以下语句显式给记录集加共享锁或排他锁：\n\n\n共享锁（S）：SELECT * FROM table_name WHERE … LOCK IN SHARE MODE。 其他 session 仍然可以查询记录，并也可以对该记录加 share mode 的共享锁。但是如果当前事务需要对该记录进行更新操作，则很有可能造成死锁。\n排他锁（X)：SELECT * FROM table_name WHERE … FOR UPDATE。其他 session 可以查询该记录，但是不能对该记录加共享锁或排他锁，而是等待获得锁\n\n\n\nInnoDB的间隙锁：当我们用范围条件而不是相等条件检索数据，并请求共享或排他锁时，InnoDB会给符合条件的已有数据记录的索引项加锁；对于键值在条件范围内但并不存在的记录，叫做“间隙（GAP)”，InnoDB也会对这个“间隙”加锁，这种锁机制就是所谓的间隙锁（Next-Key锁）。\n很显然，在使用范围条件检索并锁定记录时，InnoDB这种加锁机制会阻塞符合条件范围内键值的并发插入，这往往会造成严重的锁等待。因此，在实际应用开发中，尤其是并发插入比较多的应用，我们要尽量优化业务逻辑，尽量使用相等条件来访问更新数据，避免使用范围条件。\nInnoDB使用间隙锁的目的：\n\n防止幻读，以满足相关隔离级别的要求；\n满足恢复和复制的需要；\n\n死锁（Deadlock Free）\n死锁产生：\n\n\n死锁是指两个或多个事务在同一资源上相互占用，并请求锁定对方占用的资源，从而导致恶性循环。\n当事务试图以不同的顺序锁定资源时，就可能产生死锁。多个事务同时锁定同一个资源时也可能会产生死锁。\n锁的行为和顺序和存储引擎相关。以同样的顺序执行语句，有些存储引擎会产生死锁有些不会——死锁有双重原因：真正的数据冲突；存储引擎的实现方式。\n\n\n检测死锁：数据库系统实现了各种死锁检测和死锁超时的机制。InnoDB存储引擎能检测到死锁的循环依赖并立即返回一个错误。\n\n死锁恢复：死锁发生以后，只有部分或完全回滚其中一个事务，才能打破死锁，InnoDB目前处理死锁的方法是，将持有最少行级排他锁的事务进行回滚。所以事务型应用程序在设计时必须考虑如何处理死锁，多数情况下只需要重新执行因死锁回滚的事务即可。\n\n外部锁的死锁检测：发生死锁后，InnoDB 一般都能自动检测到，并使一个事务释放锁并回退，另一个事务获得锁，继续完成事务。但在涉及外部锁，或涉及表锁的情况下，InnoDB 并不能完全自动检测到死锁， 这需要通过设置锁等待超时参数 innodb_lock_wait_timeout 来解决\n\n死锁影响性能：死锁会影响性能而不是会产生严重错误，因为InnoDB会自动检测死锁状况并回滚其中一个受影响的事务。在高并发系统上，当许多线程等待同一个锁时，死锁检测可能导致速度变慢。 有时当发生死锁时，禁用死锁检测（使用innodb_deadlock_detect配置选项）可能会更有效，这时可以依赖innodb_lock_wait_timeout设置进行事务回滚。\n\n\n","slug":"mysql/mysql_lock","date":"2020-01-03T10:32:47.000Z","categories_index":"学习记录","tags_index":"Mysql","author_index":"Polnareff"}]